{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khatiwada/tuple-union/env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import _pickle as cPickle\n",
    "from numpy.linalg import norm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import utilities as utl\n",
    "from sklearn.model_selection import train_test_split\n",
    "import prepare_dataset_utilities as prepare_utl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use existing TUS benchmark with SANTOS relabel, a design decision to discuss about.\n",
    "benchmark_name = \"tus_benchmark\"\n",
    "groundtruth_file_path = r\"data\" + os.sep + benchmark_name + os.sep + \"groundtruth.csv\"\n",
    "table_location = r\"data\"+ os.sep + benchmark_name\n",
    "separator = \",\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial_num</th>\n",
       "      <th>query_table</th>\n",
       "      <th>intent_col_index</th>\n",
       "      <th>data_lake_table</th>\n",
       "      <th>intent_col_name</th>\n",
       "      <th>tree_level</th>\n",
       "      <th>unionable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>t_1934eacab8c57857____c4_1____0.csv</td>\n",
       "      <td>1</td>\n",
       "      <td>t_1934eacab8c57857____c2_0____0.csv</td>\n",
       "      <td>Country/region name</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>t_1934eacab8c57857____c4_1____0.csv</td>\n",
       "      <td>1</td>\n",
       "      <td>t_1934eacab8c57857____c2_0____1.csv</td>\n",
       "      <td>Country/region name</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>t_1934eacab8c57857____c4_1____0.csv</td>\n",
       "      <td>1</td>\n",
       "      <td>t_1934eacab8c57857____c2_0____2.csv</td>\n",
       "      <td>Country/region name</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>t_1934eacab8c57857____c4_1____0.csv</td>\n",
       "      <td>1</td>\n",
       "      <td>t_1934eacab8c57857____c2_0____3.csv</td>\n",
       "      <td>Country/region name</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>t_1934eacab8c57857____c4_1____0.csv</td>\n",
       "      <td>1</td>\n",
       "      <td>t_1934eacab8c57857____c2_0____4.csv</td>\n",
       "      <td>Country/region name</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12156</th>\n",
       "      <td>12157</td>\n",
       "      <td>t_356fc1eaad97f93b____c18_0____4.csv</td>\n",
       "      <td>2</td>\n",
       "      <td>t_356fc1eaad97f93b____c23_0____0.csv</td>\n",
       "      <td>Location</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12157</th>\n",
       "      <td>12158</td>\n",
       "      <td>t_356fc1eaad97f93b____c18_0____4.csv</td>\n",
       "      <td>2</td>\n",
       "      <td>t_356fc1eaad97f93b____c23_0____1.csv</td>\n",
       "      <td>Location</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12158</th>\n",
       "      <td>12159</td>\n",
       "      <td>t_356fc1eaad97f93b____c18_0____4.csv</td>\n",
       "      <td>2</td>\n",
       "      <td>t_356fc1eaad97f93b____c23_0____2.csv</td>\n",
       "      <td>Location</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12159</th>\n",
       "      <td>12160</td>\n",
       "      <td>t_356fc1eaad97f93b____c18_0____4.csv</td>\n",
       "      <td>2</td>\n",
       "      <td>t_356fc1eaad97f93b____c23_0____3.csv</td>\n",
       "      <td>Location</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12160</th>\n",
       "      <td>12161</td>\n",
       "      <td>t_356fc1eaad97f93b____c18_0____4.csv</td>\n",
       "      <td>2</td>\n",
       "      <td>t_356fc1eaad97f93b____c23_0____4.csv</td>\n",
       "      <td>Location</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12161 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       serial_num                           query_table  intent_col_index  \\\n",
       "0               1   t_1934eacab8c57857____c4_1____0.csv                 1   \n",
       "1               2   t_1934eacab8c57857____c4_1____0.csv                 1   \n",
       "2               3   t_1934eacab8c57857____c4_1____0.csv                 1   \n",
       "3               4   t_1934eacab8c57857____c4_1____0.csv                 1   \n",
       "4               5   t_1934eacab8c57857____c4_1____0.csv                 1   \n",
       "...           ...                                   ...               ...   \n",
       "12156       12157  t_356fc1eaad97f93b____c18_0____4.csv                 2   \n",
       "12157       12158  t_356fc1eaad97f93b____c18_0____4.csv                 2   \n",
       "12158       12159  t_356fc1eaad97f93b____c18_0____4.csv                 2   \n",
       "12159       12160  t_356fc1eaad97f93b____c18_0____4.csv                 2   \n",
       "12160       12161  t_356fc1eaad97f93b____c18_0____4.csv                 2   \n",
       "\n",
       "                            data_lake_table      intent_col_name  tree_level  \\\n",
       "0       t_1934eacab8c57857____c2_0____0.csv  Country/region name           2   \n",
       "1       t_1934eacab8c57857____c2_0____1.csv  Country/region name           2   \n",
       "2       t_1934eacab8c57857____c2_0____2.csv  Country/region name           2   \n",
       "3       t_1934eacab8c57857____c2_0____3.csv  Country/region name           2   \n",
       "4       t_1934eacab8c57857____c2_0____4.csv  Country/region name           2   \n",
       "...                                     ...                  ...         ...   \n",
       "12156  t_356fc1eaad97f93b____c23_0____0.csv             Location           2   \n",
       "12157  t_356fc1eaad97f93b____c23_0____1.csv             Location           2   \n",
       "12158  t_356fc1eaad97f93b____c23_0____2.csv             Location           2   \n",
       "12159  t_356fc1eaad97f93b____c23_0____3.csv             Location           2   \n",
       "12160  t_356fc1eaad97f93b____c23_0____4.csv             Location           2   \n",
       "\n",
       "       unionable  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              1  \n",
       "4              1  \n",
       "...          ...  \n",
       "12156          1  \n",
       "12157          1  \n",
       "12158          1  \n",
       "12159          1  \n",
       "12160          1  \n",
       "\n",
       "[12161 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groundtruth_file = pd.read_csv(groundtruth_file_path)\n",
    "# If a benchmark only contains unionable pairs, add unionable column with all 1 values. Eg. tus benchmark\n",
    "if \"unionable\" not in groundtruth_file.columns:\n",
    "    groundtruth_file['unionable'] = 1\n",
    "# groundtruth_file['unionable'] = groundtruth_file['unionable'].replace(2, 1)\n",
    "groundtruth_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the ground truth pairs.\n",
    "groundtruth_positive_dictionary = {}\n",
    "groundtruth_negative_dictionary = {} # this is for negative pairs from the same cluster.\n",
    "for id, row in groundtruth_file.iterrows():\n",
    "    if str(row['unionable']) == \"1\":\n",
    "        if row['query_table'] in groundtruth_positive_dictionary:\n",
    "            groundtruth_positive_dictionary[row['query_table']].add(row['data_lake_table'])\n",
    "        else:\n",
    "            groundtruth_positive_dictionary[row['query_table']] = {row['data_lake_table']}\n",
    "    else:\n",
    "        if row['query_table'] in groundtruth_negative_dictionary:\n",
    "            groundtruth_negative_dictionary[row['query_table']].add(row['data_lake_table'])\n",
    "        else:\n",
    "            groundtruth_negative_dictionary[row['query_table']] = {row['data_lake_table']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total queries: 125\n",
      "['t_c701386b7c10b107____c11_0____3.csv', 't_356fc1eaad97f93b____c12_1____2.csv', 't_356fc1eaad97f93b____c16_1____0.csv', 't_1934eacab8c57857____c12_1____2.csv', 't_1934eacab8c57857____c11_0____4.csv']\n"
     ]
    }
   ],
   "source": [
    "all_query_tables = list(set(groundtruth_positive_dictionary.keys()).union(set(groundtruth_negative_dictionary.keys())))\n",
    "print(\"Total queries:\", len(all_query_tables))\n",
    "print(all_query_tables[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data lake tables: 1530\n",
      "['t_013a2f8c584d44d7____c10_0____0.csv', 't_013a2f8c584d44d7____c10_0____1.csv', 't_013a2f8c584d44d7____c10_0____2.csv', 't_013a2f8c584d44d7____c10_0____3.csv', 't_013a2f8c584d44d7____c10_0____4.csv']\n"
     ]
    }
   ],
   "source": [
    "all_data_lake_tables = glob.glob(table_location + os.sep + \"datalake/*\")\n",
    "all_data_lake_tables = [table.rsplit(os.sep,1)[-1] for table in all_data_lake_tables]\n",
    "print(\"Total data lake tables:\", len(all_data_lake_tables))\n",
    "print(all_data_lake_tables[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count same:  125\n",
      "Count different:  10690\n",
      "Total samples:  10815\n",
      "[('t_c701386b7c10b107____c12_1____4.csv', 't_c701386b7c10b107____c20_0____4.csv'), ('t_1934eacab8c57857____c12_1____2.csv', 't_1934eacab8c57857____c15_0____2.csv'), ('t_67c3f7ce5eab8804____c6_0____0.csv', 't_356fc1eaad97f93b____c18_1____3.csv'), ('t_93f3d6f7fc6aa6ff____c13_1____2.csv', 't_93f3d6f7fc6aa6ff____c16_0____2.csv'), ('t_c701386b7c10b107____c20_1____2.csv', 't_c701386b7c10b107____c11_1____3.csv')]\n"
     ]
    }
   ],
   "source": [
    "# Prepare positive table pairs. Any table pairs marked as unionable in the ground truth are positive samples.\n",
    "positive_sample_pairs = set()\n",
    "for table1 in groundtruth_positive_dictionary:\n",
    "    current_positives = groundtruth_positive_dictionary[table1]\n",
    "    positive_sample_pairs.add((table1,table1)) # to ensure that the same table is there.\n",
    "    for table2 in current_positives:\n",
    "        if (table2, table1) not in positive_sample_pairs:\n",
    "            positive_sample_pairs.add((table1,table2))\n",
    "\n",
    "positive_same_table = set()\n",
    "positive_different_table = set()\n",
    "for item in positive_sample_pairs:\n",
    "    if item[0] == item[1]:\n",
    "        positive_same_table.add(item)\n",
    "    else:\n",
    "        positive_different_table.add(item)\n",
    "print(\"Count same: \", len(positive_same_table))\n",
    "print(\"Count different: \", len(positive_different_table))\n",
    "print(\"Total samples: \", len(positive_sample_pairs))\n",
    "\n",
    "print(list(positive_sample_pairs)[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count same cluster:  13130\n",
      "Count different cluster:  165770\n",
      "Total samples:  178900\n",
      "[('t_1934eacab8c57857____c11_0____1.csv', 't_93f3d6f7fc6aa6ff____c13_0____2.csv'), ('t_c701386b7c10b107____c12_1____1.csv', 't_ca85e8f9eef5b9d5____c10_0____4.csv'), ('t_c701386b7c10b107____c14_0____0.csv', 't_1934eacab8c57857____c12_1____3.csv'), ('t_c701386b7c10b107____c20_1____0.csv', 't_356fc1eaad97f93b____c11_1____0.csv'), ('t_93f3d6f7fc6aa6ff____c13_1____0.csv', 't_1934eacab8c57857____c1_0____2.csv')]\n"
     ]
    }
   ],
   "source": [
    "negative_same_cluster = set()\n",
    "negative_different_cluster = set()\n",
    "negative_sample_pairs = set()\n",
    "if len(groundtruth_negative_dictionary) > 0: # this is for ugen or other similar benchmarks with non-unionable tables marked in the groundtruth, may need update for other benchmarks.\n",
    "    for table1 in groundtruth_negative_dictionary:\n",
    "        current_negatives = groundtruth_negative_dictionary[table1]\n",
    "        for table2 in current_negatives:\n",
    "            if (table1, table2) in positive_sample_pairs or (table2, table1) in positive_sample_pairs:\n",
    "                print(\"Red flag!!! The table pair in negative sample is found in positive sample.\")\n",
    "            else:\n",
    "                if (table2, table1) not in negative_same_cluster:\n",
    "                    negative_same_cluster.add((table1,table2))\n",
    "\n",
    "    for query in all_query_tables:\n",
    "        for datalake in all_data_lake_tables:\n",
    "            if (query,datalake) in positive_sample_pairs or (datalake, query) in positive_sample_pairs or (query,datalake) in negative_same_cluster or (datalake, query) in negative_same_cluster:\n",
    "                continue\n",
    "            else:\n",
    "                negative_different_cluster.add((query, datalake))\n",
    "    negative_sample_pairs = negative_same_cluster.union(negative_different_cluster)\n",
    "\n",
    "else: # this is for tus benchmark, may need update for other benchmarks.\n",
    "    # Prepare negative table pairs. Any table pairs with one table as a query table marked as non-unionable in the ground truth are negative samples.\n",
    "    for query in all_query_tables:\n",
    "        for datalake in all_data_lake_tables:\n",
    "            if (query,datalake) not in positive_sample_pairs and (datalake, query) not in positive_sample_pairs:\n",
    "                negative_sample_pairs.add((query, datalake))\n",
    "\n",
    "    # t_1934eacab8c57857____c4_1____0.csv\n",
    "    for item in negative_sample_pairs:\n",
    "        if item[0].split(\"____\",1)[0] == item[1].split(\"____\",1)[0]:\n",
    "            negative_same_cluster.add(item)\n",
    "        else:\n",
    "            negative_different_cluster.add(item)\n",
    "\n",
    "print(\"Count same cluster: \", len(negative_same_cluster))\n",
    "print(\"Count different cluster: \", len(negative_different_cluster))\n",
    "print(\"Total samples: \", len(negative_sample_pairs))\n",
    "\n",
    "print(list(negative_sample_pairs)[0:5])\n",
    "\n",
    "if len(negative_sample_pairs.intersection(positive_sample_pairs)) > 0:\n",
    "    print(\"Red flag!!! Overlap found between positive and negative samples.\")\n",
    "    # print(len(negative_sample_pairs.intersection(positive_sample_pairs)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select up to 5 tuples from each positive and negative pairs. Note that is going to be random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total positive samples selected from the same table: 2687\n",
      "Total positive samples selected from cross (different) tables: 27313\n",
      "Total positive samples selected: 30000\n",
      "Total negative samples selected from the same table cluster: 15000\n",
      "Total negative samples selected from different table cluster: 15000\n",
      "Total negative samples selected: 30000\n"
     ]
    }
   ],
   "source": [
    "# selecting 50k positive samples and 50k negative samples\n",
    "# positive: ~ 5k from the same table schema type (125 pairs, ~ 40 from each) and ~45k from different schema table type (10690 pairs, ~ 4 from each). The same table is easy case for which BERT is already working well. So, focusing here on different tables.\n",
    "# negative: ~ 25k from the same table cluster (25000 pairs, ~ 1 from each) and ~ 25k from different table clusters (166125 pairs, ~ 1/6 from each )\n",
    "\n",
    "# Note that we have more negatives, so this decision is made to solve the imbalance. Indeed it does not matter how much data is available in the open-world. \n",
    "# We should care the closed-world case for the model.\n",
    "\n",
    "selected_positive_tuples_same = prepare_utl.CreateSampleDataPoints(positive_same_table, 5, \"1\", table_location, separator= separator, pairs = \"quadratic\") # pairs = quadratic or linear\n",
    "print(\"Total positive samples selected from the same table:\", len(selected_positive_tuples_same))\n",
    "prepare_utl.SaveSampleDataPoints(r\"finetune_data\" + os.sep + benchmark_name + \"_corrected\" + os.sep + \"positive_same_table.txt\", selected_positive_tuples_same)\n",
    "\n",
    "selected_positive_tuples_different = prepare_utl.CreateSampleDataPoints(positive_different_table, 5, \"1\", table_location, separator= separator, pairs = \"quadratic\")\n",
    "#balance the dataset:\n",
    "# if benchmark_name == \"ugen_benchmark\":\n",
    "selected_positive_tuples_different = list(selected_positive_tuples_different)\n",
    "random.shuffle(selected_positive_tuples_different)\n",
    "selected_positive_tuples_different = set(selected_positive_tuples_different[0:27313]) #to balance the dataset for ugen benchmark\n",
    "print(\"Total positive samples selected from cross (different) tables:\", len(selected_positive_tuples_different))\n",
    "prepare_utl.SaveSampleDataPoints(r\"finetune_data\" + os.sep + benchmark_name + \"_corrected\" + os.sep + \"positive_different_tables.txt\", selected_positive_tuples_different)\n",
    "\n",
    "all_positive_samples = selected_positive_tuples_same.union(selected_positive_tuples_different)\n",
    "print(\"Total positive samples selected:\", len(all_positive_samples))\n",
    "prepare_utl.SaveSampleDataPoints(r\"finetune_data\"+ os.sep + benchmark_name + \"_corrected\" +os.sep + \"all_positive_samples.txt\", all_positive_samples)\n",
    "\n",
    "\n",
    "selected_negative_tuples_same = prepare_utl.CreateSampleDataPoints(negative_same_cluster, 5, \"0\", table_location , separator= separator, pairs = \"quadratic\")\n",
    "#balance the dataset:\n",
    "# if benchmark_name == \"ugen_benchmark\":\n",
    "selected_negative_tuples_same = list(selected_negative_tuples_same)\n",
    "random.shuffle(selected_negative_tuples_same)\n",
    "selected_negative_tuples_same = set(selected_negative_tuples_same[0:15000]) #to balance the dataset for ugen benchmark\n",
    "print(\"Total negative samples selected from the same table cluster:\", len(selected_negative_tuples_same))\n",
    "prepare_utl.SaveSampleDataPoints(r\"finetune_data\"+ os.sep + benchmark_name + \"_corrected\" + os.sep + \"negative_same_table_cluster.txt\", selected_negative_tuples_same)\n",
    "\n",
    "negative_different_sample_ratio = 1/6 # reduce negative different tables to 1/6 by sampling\n",
    "negative_different_sample_size = round(len(negative_different_cluster) * negative_different_sample_ratio)\n",
    "negative_different_cluster_sampled = random.sample(list(negative_different_cluster), k = negative_different_sample_size)\n",
    "selected_negative_tuples_different = prepare_utl.CreateSampleDataPoints(negative_different_cluster_sampled, 5, \"0\", table_location , separator= separator, pairs = \"linear\")\n",
    "#balance the dataset:\n",
    "# if benchmark_name == \"ugen_benchmark\":\n",
    "selected_negative_tuples_different = list(selected_negative_tuples_different)\n",
    "random.shuffle(selected_negative_tuples_different)\n",
    "selected_negative_tuples_different = set(selected_negative_tuples_different[0:15000]) #to balance the dataset for ugen benchmark\n",
    "\n",
    "print(\"Total negative samples selected from different table cluster:\", len(selected_negative_tuples_different))\n",
    "prepare_utl.SaveSampleDataPoints(r\"finetune_data\" + os.sep + benchmark_name + \"_corrected\" + os.sep + \"negative_different_table_cluster.txt\", selected_negative_tuples_different)\n",
    "\n",
    "all_negative_samples = selected_negative_tuples_same.union(selected_negative_tuples_different)\n",
    "print(\"Total negative samples selected:\", len(all_negative_samples))\n",
    "prepare_utl.SaveSampleDataPoints(r\"finetune_data\"+ os.sep + benchmark_name + \"_corrected\" + os.sep + \"all_negative_samples.txt\", all_negative_samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
