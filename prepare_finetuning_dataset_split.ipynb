{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khatiwada/tuple-union/env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import _pickle as cPickle\n",
    "from numpy.linalg import norm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import utilities as utl\n",
    "from sklearn.model_selection import train_test_split\n",
    "import prepare_dataset_utilities as prepare_utl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_name = \"tus_benchmark_corrected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_positive_samples = prepare_utl.LoadSampleDataPoints(r\"finetune_data\" + os.sep + benchmark_name + os.sep + \"all_positive_samples.txt\")\n",
    "all_negative_samples = prepare_utl.LoadSampleDataPoints(r\"finetune_data\" + os.sep + benchmark_name + os.sep + \"all_negative_samples.txt\")\n",
    "all_mixed_samples = all_positive_samples.union(all_negative_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_same_table = prepare_utl.LoadSampleDataPoints(r\"finetune_data\" + os.sep + benchmark_name + os.sep + \"positive_same_table.txt\")\n",
    "positive_different_tables = prepare_utl.LoadSampleDataPoints(r\"finetune_data\" + os.sep + benchmark_name + os.sep + \"positive_different_tables.txt\")\n",
    "negative_same_table_cluster = prepare_utl.LoadSampleDataPoints(r\"finetune_data\" + os.sep + benchmark_name + os.sep + \"negative_same_table_cluster.txt\")\n",
    "negative_different_table_cluster = prepare_utl.LoadSampleDataPoints(r\"finetune_data\" + os.sep + benchmark_name + os.sep + \"negative_different_table_cluster.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive same:\n",
      "Successful! No leakage found during splitting.\n",
      "Train size: 1881\n",
      "Test size: 403\n",
      "Valid size: 403\n",
      "Positive different:\n",
      "Successful! No leakage found during splitting.\n",
      "Train size: 19121\n",
      "Test size: 4096\n",
      "Valid size: 4096\n",
      "Negative same:\n",
      "Successful! No leakage found during splitting.\n",
      "Train size: 10500\n",
      "Test size: 2250\n",
      "Valid size: 2250\n",
      "Negative different:\n",
      "Successful! No leakage found during splitting.\n",
      "Train size: 10500\n",
      "Test size: 2250\n",
      "Valid size: 2250\n"
     ]
    }
   ],
   "source": [
    "def SplitEachSetTrainTest(all_samples, ratio = 0.15):\n",
    "    # for faster train-test split, index the strings to make input to test_train_split smaller.\n",
    "    all_samples_set = set()\n",
    "    for item in all_samples:\n",
    "        item = item.rsplit(\"\\t\",1)\n",
    "        if len(item) == 2:\n",
    "            all_samples_set.add((item[0], item[1]))\n",
    "    all_samples = list(all_samples_set)\n",
    "    train_data, test_data, valid_data = prepare_utl.SplitTrainTestValid(all_samples, ratio)\n",
    "    print(\"Train size:\", len(train_data))\n",
    "    print(\"Test size:\", len(test_data))\n",
    "    print(\"Valid size:\", len(valid_data))\n",
    "    return train_data, test_data, valid_data\n",
    "\n",
    "print(\"Positive same:\")\n",
    "positive_same_train, positive_same_test, positive_same_valid = SplitEachSetTrainTest(positive_same_table)\n",
    "print(\"Positive different:\")\n",
    "positive_different_train, positive_different_test, positive_different_valid = SplitEachSetTrainTest(positive_different_tables)\n",
    "print(\"Negative same:\")\n",
    "negative_same_train, negative_same_test, negative_same_valid = SplitEachSetTrainTest(negative_same_table_cluster)\n",
    "print(\"Negative different:\")\n",
    "negative_different_train, negative_different_test, negative_different_valid = SplitEachSetTrainTest(negative_different_table_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_out = positive_same_train.pop()\n",
    "positive_same_test.add(pop_out)\n",
    "\n",
    "pop_out = positive_different_train.pop()\n",
    "positive_different_valid.add(pop_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No leakage between test and train\n",
      "No leakage between test and valid\n",
      "No leakage between test and valid\n",
      "Train size: 42000\n",
      "Test size: 9000\n",
      "Valid size: 9000\n"
     ]
    }
   ],
   "source": [
    "train_data_points = positive_same_train.union(positive_different_train).union(negative_same_train).union(negative_different_train)\n",
    "test_data_points = positive_same_test.union(positive_different_test).union(negative_same_test).union(negative_different_test)\n",
    "valid_data_points = positive_same_valid.union(positive_different_valid).union(negative_same_valid).union(negative_different_valid)\n",
    "\n",
    "\n",
    "if len(test_data_points.intersection(train_data_points)) > 0:\n",
    "    print(\"Leakage between test and train\")\n",
    "    test_data_points = test_data_points - train_data_points\n",
    "if len(test_data_points.intersection(valid_data_points)) > 0:\n",
    "    print(\"Leakage between test and valid\")\n",
    "    valid_data_points = valid_data_points - test_data_points\n",
    "if len(valid_data_points.intersection(train_data_points)) > 0:\n",
    "    print(\"Leakage between valid and train\")\n",
    "    valid_data_points = valid_data_points - train_data_points\n",
    "\n",
    "if len(test_data_points.intersection(train_data_points)) > 0:\n",
    "    print(\"Leakage between test and train\")\n",
    "else:\n",
    "    print(\"No leakage between test and train\")\n",
    "if len(test_data_points.intersection(valid_data_points)) > 0:\n",
    "    print(\"Leakage between test and valid\")\n",
    "else:\n",
    "    print(\"No leakage between test and valid\")\n",
    "if len(valid_data_points.intersection(train_data_points)) > 0:\n",
    "    print(\"Leakage between valid and train\")\n",
    "else:\n",
    "    print(\"No leakage between test and valid\")\n",
    "print(\"Train size:\", len(train_data_points))\n",
    "print(\"Test size:\", len(test_data_points))\n",
    "print(\"Valid size:\", len(valid_data_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train positive: 21000\n",
      "Train negative: 21000\n",
      "Test positive: 4500\n",
      "Test negative: 4500\n",
      "Valid positive: 4500\n",
      "Valid negative: 4500\n"
     ]
    }
   ],
   "source": [
    "train_positive, train_negative = prepare_utl.CountClassLabelSize(train_data_points)\n",
    "test_positive, test_negative = prepare_utl.CountClassLabelSize(test_data_points)\n",
    "valid_positive, valid_negative = prepare_utl.CountClassLabelSize(valid_data_points)\n",
    "print(\"Train positive:\", train_positive)\n",
    "print(\"Train negative:\", train_negative)\n",
    "print(\"Test positive:\", test_positive)\n",
    "print(\"Test negative:\", test_negative)\n",
    "print(\"Valid positive:\", valid_positive)\n",
    "print(\"Valid negative:\", valid_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_utl.SaveDatasetAsTSVFile(train_data_points, r\"data/finetune_data\" + os.sep + benchmark_name + os.sep + \"train\")\n",
    "prepare_utl.SaveDatasetAsTSVFile(test_data_points, r\"data/finetune_data\" + os.sep + benchmark_name + os.sep + \"test\")\n",
    "prepare_utl.SaveDatasetAsTSVFile(valid_data_points, r\"data/finetune_data\" + os.sep + benchmark_name + os.sep + \"valid\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
